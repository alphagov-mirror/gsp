global:
  runningOnAws: false
  cluster:
    name: "my-cluster"
    domain: "example.com"
    domain_id: ""
    egressIpAddresses: ["127.0.0.1"]
    releaseVersion: master
  account:
    name: ""
  roles:
    canary: ""
  cloudHsm:
    enabled: false
    ip: "127.0.0.1"
  kubeApiService:
    endpointCidrs: []
  # move these to gsp-namespace terraform output
  canary:
    repository: ""
    verificationKeys: []
  ci:
    privateKey: ""
    publicKey: ""
  concourse:
    enabled: true
  harbor:
    enabled: true

adminRoleARNs: []
permittedRolesRegex: ""

githubAPIToken: ""

googleOauthClientId: ""
googleOauthClientSecret: ""

httpsEgressSafelist: []
httpEgressSafelist: []


# users:
# - name: chris.farmiloe
#   roleARN: xxx/user.chris.farmiloe
#   groups:
#   - sandbox-admin
#   - sandbox-sre
#   - sandbox-canary-dev
# - name: sam.crang
#   roleARN: xxx/user.sam.crang
#   groups:
#   - sandbox-canary-dev

# namespaces:
# - name: verify-metadata-controller
#   owner: alphagov
#   repository: verify-metadata-controller
#   branch: master
#   path: ci
#   permittedRolesRegex: "^$"
#   requiredApprovalCount: 2
#   scope: cluster

cluster-autoscaler:
  extraArgs:
    balance-similar-node-groups: true
  image:
    tag: v1.14.5 # upgrade this when upgrading kubernetes
  rbac:
    create: true
  priorityClassName: gsp-critical
  serviceMonitor:
    enabled: true
    namespace: gsp-system
  nodeSelector:
    node-role.kubernetes.io/cluster-management: ""
  tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/cluster-management
  replicaCount: 2

kiam:
  nameOverride:
  fullnameOverride:
  server:
    tlsFiles:
      ca: "NADA"
      cert: "NADA"
      key: "NADA"
    nodeSelector:
      node-role.kubernetes.io/cluster-management: ""
    tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/cluster-management
    log:
      level: info
    probes:
      serverAddress: 127.0.0.1
    extraHostPathMounts:
      - name: ssl-certs
        mountPath: /etc/ssl/certs/ca-certificates.crt
        hostPath: /etc/pki/tls/certs/ca-bundle.crt
        readOnly: true
    serviceAnnotations:
      networking.istio.io/exportTo: "."
    priorityClassName: gsp-critical
  agent:
    gatewayTimeoutCreation: 30s
    host:
      iptables: true
    tlsFiles:
      ca: "NADA"
      cert: "NADA"
      key: "NADA"
    log:
      level: info
    whiteListRouteRegexp: "^(/latest/meta-data/placement/availability-zone)$"
    tolerations:
    - key: node-role.kubernetes.io/ci
      effect: NoSchedule
      operator: Exists
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      operator: Exists
    priorityClassName: gsp-critical

fluentd-cloudwatch:
  resources:
    limits:
      memory: 512Mi
    requests:
      memory: 512Mi
  rbac:
    create: true
  awsRegion: eu-west-2
  updateStrategy:
    type: RollingUpdate
  volumeMounts:
    - name: runlogjournal
      mountPath: /run/log/journal
      readOnly: true
    - name: dmesg
      mountPath: /var/log/dmesg
      readOnly: true
  volumes:
    - name: runlogjournal
      hostPath:
        path: /run/log/journal
    - name: dmesg
      hostPath:
        path: /var/log/dmesg
  tolerations:
    - key: node-role.kubernetes.io/master
      effect: NoSchedule
  priorityClassName: gsp-critical
  data:
    fluent.conf: |
      @include containers.conf
      @include systemd.conf
      @include host.conf

      <match fluent.**>
        @type null
      </match>
    containers.conf: |
      <source>
        @type tail
        @id in_tail_container_logs
        @label @containers
        path /var/log/containers/*.log
        exclude_path ["/var/log/containers/cloudwatch-agent*", "/var/log/containers/fluentd*"]
        pos_file /var/log/fluentd-containers.log.pos
        tag *
        read_from_head true
        <parse>
          @type json
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </parse>
      </source>

      <source>
        @type tail
        @id in_tail_cwagent_logs
        @label @cwagentlogs
        path /var/log/containers/cloudwatch-agent*
        pos_file /var/log/cloudwatch-agent.log.pos
        tag *
        read_from_head true
        <parse>
          @type json
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </parse>
      </source>

      <source>
        @type tail
        @id in_tail_fluentd_logs
        @label @fluentdlogs
        path /var/log/containers/fluentd*
        pos_file /var/log/fluentd.log.pos
        tag *
        read_from_head true
        <parse>
          @type json
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </parse>
      </source>

      <label @fluentdlogs>
        <filter **>
          @type kubernetes_metadata
          @id filter_kube_metadata_fluentd
        </filter>

        <filter **>
          @type record_transformer
          @id filter_fluentd_stream_transformer
          <record>
            stream_name ${tag_parts[3]}
          </record>
        </filter>

        <match **>
          @type relabel
          @label @NORMAL
        </match>
      </label>

      <label @containers>
        <filter **>
          @type kubernetes_metadata
          @id filter_kube_metadata
        </filter>

        <filter **>
          @type record_transformer
          @id filter_containers_stream_transformer
          <record>
            stream_name ${tag_parts[3]}
          </record>
        </filter>

        <filter **>
          @type concat
          key log
          multiline_start_regexp /^\S/
          separator ""
          flush_interval 5
          timeout_label @NORMAL
        </filter>

        <match **>
          @type relabel
          @label @NORMAL
        </match>
      </label>

      <label @cwagentlogs>
        <filter **>
          @type kubernetes_metadata
          @id filter_kube_metadata_cwagent
        </filter>

        <filter **>
          @type record_transformer
          @id filter_cwagent_stream_transformer
          <record>
            stream_name ${tag_parts[3]}
          </record>
        </filter>

        <filter **>
          @type concat
          key log
          multiline_start_regexp /^\d{4}[-/]\d{1,2}[-/]\d{1,2}/
          separator ""
          flush_interval 5
          timeout_label @NORMAL
        </filter>

        <match **>
          @type relabel
          @label @NORMAL
        </match>
      </label>

      <label @NORMAL>
        <match **>
          @type cloudwatch_logs
          @id out_cloudwatch_logs_containers
          region "#{ENV.fetch('AWS_REGION')}"
          log_group_name "/aws/containerinsights/#{ENV.fetch('CLUSTER_NAME')}/application"
          log_stream_name_key stream_name
          remove_log_stream_name_key true
          auto_create_stream true
          <buffer>
            flush_interval 5
            chunk_limit_size 2m
            queued_chunks_limit_size 32
            retry_forever true
          </buffer>
        </match>
      </label>
    systemd.conf: |
      <source>
        @type systemd
        @id in_systemd_kubelet
        @label @systemd
        filters [{ "_SYSTEMD_UNIT": "kubelet.service" }]
        <entry>
          field_map {"MESSAGE": "message", "_HOSTNAME": "hostname", "_SYSTEMD_UNIT": "systemd_unit"}
          field_map_strict true
        </entry>
        path /var/log/journal
        <storage>
          @type local
          persistent true
          path /var/log/fluentd-journald-kubelet-pos.json
        </storage>
        read_from_head true
        tag kubelet.service
      </source>

      <source>
        @type systemd
        @id in_systemd_kubeproxy
        @label @systemd
        filters [{ "_SYSTEMD_UNIT": "kubeproxy.service" }]
        <entry>
          field_map {"MESSAGE": "message", "_HOSTNAME": "hostname", "_SYSTEMD_UNIT": "systemd_unit"}
          field_map_strict true
        </entry>
        path /var/log/journal
        <storage>
          @type local
          persistent true
          path /var/log/fluentd-journald-kubeproxy-pos.json
        </storage>
        read_from_head true
        tag kubeproxy.service
      </source>

      <source>
        @type systemd
        @id in_systemd_docker
        @label @systemd
        filters [{ "_SYSTEMD_UNIT": "docker.service" }]
        <entry>
          field_map {"MESSAGE": "message", "_HOSTNAME": "hostname", "_SYSTEMD_UNIT": "systemd_unit"}
          field_map_strict true
        </entry>
        path /var/log/journal
        <storage>
          @type local
          persistent true
          path /var/log/fluentd-journald-docker-pos.json
        </storage>
        read_from_head true
        tag docker.service
      </source>

      <label @systemd>
        <filter **>
          @type kubernetes_metadata
          @id filter_kube_metadata_systemd
        </filter>

        <filter **>
          @type record_transformer
          @id filter_systemd_stream_transformer
          <record>
            stream_name ${tag}-${record["hostname"]}
          </record>
        </filter>

        <match **>
          @type cloudwatch_logs
          @id out_cloudwatch_logs_systemd
          region "#{ENV.fetch('AWS_REGION')}"
          log_group_name "/aws/containerinsights/#{ENV.fetch('CLUSTER_NAME')}/dataplane"
          log_stream_name_key stream_name
          auto_create_stream true
          remove_log_stream_name_key true
          <buffer>
            flush_interval 5
            chunk_limit_size 2m
            queued_chunks_limit_size 32
            retry_forever true
          </buffer>
        </match>
      </label>
    host.conf: |
      <source>
        @type tail
        @id in_tail_dmesg
        @label @hostlogs
        path /var/log/dmesg
        pos_file /var/log/dmesg.log.pos
        tag host.dmesg
        read_from_head true
        <parse>
          @type syslog
        </parse>
      </source>

      <source>
        @type tail
        @id in_tail_secure
        @label @hostlogs
        path /var/log/secure
        pos_file /var/log/secure.log.pos
        tag host.secure
        read_from_head true
        <parse>
          @type syslog
        </parse>
      </source>

      <source>
        @type tail
        @id in_tail_messages
        @label @hostlogs
        path /var/log/messages
        pos_file /var/log/messages.log.pos
        tag host.messages
        read_from_head true
        <parse>
          @type syslog
        </parse>
      </source>

      <label @hostlogs>
        <filter **>
          @type kubernetes_metadata
          @id filter_kube_metadata_host
        </filter>

        <filter **>
          @type record_transformer
          @id filter_containers_stream_transformer_host
          <record>
            stream_name ${tag}-${record["host"]}
          </record>
        </filter>

        <match host.**>
          @type cloudwatch_logs
          @id out_cloudwatch_logs_host_logs
          region "#{ENV.fetch('AWS_REGION')}"
          log_group_name "/aws/containerinsights/#{ENV.fetch('CLUSTER_NAME')}/host"
          log_stream_name_key stream_name
          remove_log_stream_name_key true
          auto_create_stream true
          <buffer>
            flush_interval 5
            chunk_limit_size 2m
            queued_chunks_limit_size 32
            retry_forever true
          </buffer>
        </match>
      </label>

  fluentdConfig: |
      <match fluent.**>
        @type null
      </match>

      <source>
        @type tail
        @id in_tail_container_logs
        @label @containers
        path /var/log/containers/*.log
        exclude_path ["/var/log/containers/cloudwatch-agent*", "/var/log/containers/fluentd*"]
        pos_file /var/log/fluentd-containers.log.pos
        tag *
        read_from_head true
        <parse>
          @type json
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </parse>
      </source>

      <source>
        @type tail
        @id in_tail_cwagent_logs
        @label @cwagentlogs
        path /var/log/containers/cloudwatch-agent*
        pos_file /var/log/cloudwatch-agent.log.pos
        tag *
        read_from_head true
        <parse>
          @type json
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </parse>
      </source>

      <source>
        @type tail
        @id in_tail_fluentd_logs
        @label @fluentdlogs
        path /var/log/containers/fluentd*
        pos_file /var/log/fluentd.log.pos
        tag *
        read_from_head true
        <parse>
          @type json
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </parse>
      </source>

      <label @fluentdlogs>
        <filter **>
          @type kubernetes_metadata
          @id filter_kube_metadata_fluentd
        </filter>

        <filter **>
          @type record_transformer
          @id filter_fluentd_stream_transformer
          <record>
            stream_name ${tag_parts[3]}
          </record>
        </filter>

        <match **>
          @type relabel
          @label @NORMAL
        </match>
      </label>

      <label @containers>
        <filter **>
          @type kubernetes_metadata
          @id filter_kube_metadata
        </filter>

        <filter **>
          @type record_transformer
          @id filter_containers_stream_transformer
          <record>
            stream_name ${tag_parts[3]}
          </record>
        </filter>

        <filter **>
          @type concat
          key log
          multiline_start_regexp /^\S/
          separator ""
          flush_interval 5
          timeout_label @NORMAL
        </filter>

        <match **>
          @type relabel
          @label @NORMAL
        </match>
      </label>

      <label @cwagentlogs>
        <filter **>
          @type kubernetes_metadata
          @id filter_kube_metadata_cwagent
        </filter>

        <filter **>
          @type record_transformer
          @id filter_cwagent_stream_transformer
          <record>
            stream_name ${tag_parts[3]}
          </record>
        </filter>

        <filter **>
          @type concat
          key log
          multiline_start_regexp /^\d{4}[-/]\d{1,2}[-/]\d{1,2}/
          separator ""
          flush_interval 5
          timeout_label @NORMAL
        </filter>

        <match **>
          @type relabel
          @label @NORMAL
        </match>
      </label>

      <label @NORMAL>
        <match **>
          @type cloudwatch_logs
          @id out_cloudwatch_logs_containers
          region "#{ENV.fetch('AWS_REGION')}"
          log_group_name "/aws/containerinsights/#{ENV.fetch('CLUSTER_NAME')}/application"
          log_stream_name_key stream_name
          remove_log_stream_name_key true
          auto_create_stream true
          <buffer>
            flush_interval 5
            chunk_limit_size 2m
            queued_chunks_limit_size 32
            retry_forever true
          </buffer>
        </match>
      </label>

      <source>
        @type systemd
        @id in_systemd_kubelet
        @label @systemd
        filters [{ "_SYSTEMD_UNIT": "kubelet.service" }]
        <entry>
          field_map {"MESSAGE": "message", "_HOSTNAME": "hostname", "_SYSTEMD_UNIT": "systemd_unit"}
          field_map_strict true
        </entry>
        path /var/log/journal
        <storage>
          @type local
          persistent true
          path /var/log/fluentd-journald-kubelet-pos.json
        </storage>
        read_from_head true
        tag kubelet.service
      </source>

      <source>
        @type systemd
        @id in_systemd_kubeproxy
        @label @systemd
        filters [{ "_SYSTEMD_UNIT": "kubeproxy.service" }]
        <entry>
          field_map {"MESSAGE": "message", "_HOSTNAME": "hostname", "_SYSTEMD_UNIT": "systemd_unit"}
          field_map_strict true
        </entry>
        path /var/log/journal
        <storage>
          @type local
          persistent true
          path /var/log/fluentd-journald-kubeproxy-pos.json
        </storage>
        read_from_head true
        tag kubeproxy.service
      </source>

      <source>
        @type systemd
        @id in_systemd_docker
        @label @systemd
        filters [{ "_SYSTEMD_UNIT": "docker.service" }]
        <entry>
          field_map {"MESSAGE": "message", "_HOSTNAME": "hostname", "_SYSTEMD_UNIT": "systemd_unit"}
          field_map_strict true
        </entry>
        path /var/log/journal
        <storage>
          @type local
          persistent true
          path /var/log/fluentd-journald-docker-pos.json
        </storage>
        read_from_head true
        tag docker.service
      </source>

      <label @systemd>
        <filter **>
          @type kubernetes_metadata
          @id filter_kube_metadata_systemd
        </filter>

        <filter **>
          @type record_transformer
          @id filter_systemd_stream_transformer
          <record>
            stream_name ${tag}-${record["hostname"]}
          </record>
        </filter>

        <match **>
          @type cloudwatch_logs
          @id out_cloudwatch_logs_systemd
          region "#{ENV.fetch('AWS_REGION')}"
          log_group_name "/aws/containerinsights/#{ENV.fetch('CLUSTER_NAME')}/dataplane"
          log_stream_name_key stream_name
          auto_create_stream true
          remove_log_stream_name_key true
          <buffer>
            flush_interval 5
            chunk_limit_size 2m
            queued_chunks_limit_size 32
            retry_forever true
          </buffer>
        </match>
      </label>

      <source>
        @type tail
        @id in_tail_dmesg
        @label @hostlogs
        path /var/log/dmesg
        pos_file /var/log/dmesg.log.pos
        tag host.dmesg
        read_from_head true
        <parse>
          @type syslog
        </parse>
      </source>

      <source>
        @type tail
        @id in_tail_secure
        @label @hostlogs
        path /var/log/secure
        pos_file /var/log/secure.log.pos
        tag host.secure
        read_from_head true
        <parse>
          @type syslog
        </parse>
      </source>

      <source>
        @type tail
        @id in_tail_messages
        @label @hostlogs
        path /var/log/messages
        pos_file /var/log/messages.log.pos
        tag host.messages
        read_from_head true
        <parse>
          @type syslog
        </parse>
      </source>

      <label @hostlogs>
        <filter **>
          @type kubernetes_metadata
          @id filter_kube_metadata_host
        </filter>

        <filter **>
          @type record_transformer
          @id filter_containers_stream_transformer_host
          <record>
            stream_name ${tag}-${record["host"]}
          </record>
        </filter>

        <match host.**>
          @type cloudwatch_logs
          @id out_cloudwatch_logs_host_logs
          region "#{ENV.fetch('AWS_REGION')}"
          log_group_name "/aws/containerinsights/#{ENV.fetch('CLUSTER_NAME')}/host"
          log_stream_name_key stream_name
          remove_log_stream_name_key true
          auto_create_stream true
          <buffer>
            flush_interval 5
            chunk_limit_size 2m
            queued_chunks_limit_size 32
            retry_forever true
          </buffer>
        </match>
      </label>

concourse:
  web:
    nameOverride: concourse-web
    replicas: 2
    additionalVolumes:
    - name: ci-web-configuration
      configMap:
        name: gsp-concourse
    additionalVolumeMounts:
    - name: ci-web-configuration
      mountPath: /web-configuration
    resources:
      requests:
        cpu: 100m
        memory: 1Gi
  monitor:
    create: true
  worker:
    nameOverride: concourse-worker
    replicas: 2
    hardAntiAffinity: true
    emptyDirSize: 60Gi
    resources:
      requests:
        cpu: 150m
        memory: 2Gi
    env:
    - name: CONCOURSE_GARDEN_DNS_PROXY_ENABLE
      value: "false"
    - name: CONCOURSE_WORKER_GARDEN_DNS_PROXY_ENABLE
      value: "false"
  secrets:
    localUsers: admin:password
  concourse:
    worker:
      logLevel: error
      ephemeral: true
      baggageclaim:
        logLevel: error
        driver: btrfs
    web:
      xFrameOptions: "allow-from: https://framesplits.cloudapps.digital/"
      logLevel: error
      auth:
        mainTeam:
          localUser: admin
      kubernetes:
        createTeamNamespaces: false
      service:
        type: ClusterIP
      prometheus:
        enabled: true
      enablePipelineAuditing: true
      enableTeamAuditing: true
  persistence:
    enabled: false
  postgresql:
    persistence:
      size: 64Gi

pipelineOperator:
  service:
    port: 443
  serviceAccountName: pipeline-operator-service-account
  image:
    repository: govsvc/concourse-operator
    tag: latest
  concourseUsername: admin
  concoursePassword: password
  concourseInsecureSkipVerify: "false"

serviceOperator:
  service:
    port: 443
  serviceAccountName: service-operator-service-account
  image:
    repository: govsvc/service-operator
    tag: latest

AWSSSMAgent:
  image:
    repository: govsvc/amazon-ssm-agent
    tag: latest

harbor:
  harborAdminPassword: ""
  chartmuseum:
    enabled: false
  logLevel: warn
  expose:
    type: ingress
    tls:
      enabled: false
  clair:
    enabled: false
  core:
    replicas: 2
  registry:
    replicas: 2
  notary:
    server:
      replicas: 4
    signer:
      replicas: 4
    tlsCA: ""
    tlsCert: ""
    tlsKey: ""

# sealed-secrets keys
secrets:
  public_certificate: ""
  private_key: ""

# concourse resource image references available in-cluster
# this lets users follow our upstream builds.
# these values will be converted into a Secret available
# in user namespaces so they can be referenced in concourse
# as ((concourse.github-resource-image)) etc.
concourseResources:
  github:
    image:
      repository: govsvc/concourse-github-resource
      tag: latest
  harbor:
    image:
      repository: govsvc/concourse-harbor-resource
      tag: latest
  task:
    image:
      repository: govsvc/task-toolbox
      tag: latest

externalDns:
  iamRoleName: ""

gatekeeper:
  enabled: true

cert-manager:
  replicaCount: 2
